{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf1720a",
   "metadata": {},
   "source": [
    "## Evaluation of Future Energy Scenarios\n",
    "\n",
    "#### Country Code & Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup environment and load the base PyPSA-Earth network for a specified country.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pypsa\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import shutil\n",
    "import pypsa\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap, to_hex\n",
    "\n",
    "#from scripts._helpers import (two_2_three_digits_country, two_digits_2_name_country)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Warning configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "# Suppress unnecessary warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Environment setup\n",
    "# ---------------------------------------------------------------------------\n",
    "# Ensure the working directory includes the 'pypsa-earth' folder\n",
    "if not os.path.isdir(\"pypsa-earth\"):\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "# Add PyPSA-Earth scripts to the system path\n",
    "scripts_path = os.path.join(os.getcwd(), \"pypsa-earth\", \"scripts\")\n",
    "sys.path.append(scripts_path)\n",
    "\n",
    "print(f\"Scripts path added: {scripts_path}\")\n",
    "assert os.path.isdir(scripts_path), f\"Path not found: {scripts_path}\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "# Define country parameters\n",
    "country_code = \"EC\"        # ISO 2-letter code (e.g., 'GH' for Ghana, 'CO' for Colombia)\n",
    "country_name = \"Ecuador\"   # Country name\n",
    "country_gadm = \"ECU\"       # ISO 3-letter GADM code\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load network\n",
    "# ---------------------------------------------------------------------------\n",
    "# Define network file location\n",
    "network_dir = os.path.join(os.getcwd(), \"pypsa-earth\", \"networks\")\n",
    "network_file = \"base.nc\"\n",
    "network_path = os.path.join(network_dir, network_file)\n",
    "\n",
    "# Load the PyPSA network\n",
    "network = pypsa.Network(network_path)\n",
    "\n",
    "print(f\"Network loaded successfully from: {network_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5c180",
   "metadata": {},
   "source": [
    "#### Mapping buses and place of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Ecuadorian transmission buses/lines colored by nominal voltage.\n",
    "\n",
    "Notes:\n",
    "- Ecuador uses 500 kV, 230 kV, 138 kV, and 69 kV per:\n",
    "  https://www.ambienteyenergia.gob.ec/wp-content/uploads/2020/01/5.-PLAN-DE-EXPANSION-DE-LA-TRANSMISION.pdf\n",
    "- Validate voltage levels later with TTDO data.\n",
    "- Optionally suppress buses without connected lines/transformers (TBD).\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import requests\n",
    "from matplotlib.colors import LinearSegmentedColormap, to_hex\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Colors for bus/line voltages\n",
    "# ---------------------------------------------------------------------\n",
    "uniques = np.sort(network.buses.v_nom.unique())\n",
    "n_unique = len(uniques)\n",
    "\n",
    "if n_unique == 1:\n",
    "    colors = [to_hex(\"#006400\")]  # dark green fallback\n",
    "else:\n",
    "    cmap = LinearSegmentedColormap.from_list(\"green_to_blue\", [\"#34F034\", \"#00008B\"])\n",
    "    colors = [to_hex(c) for c in cmap(np.linspace(0, 1, n_unique))]\n",
    "\n",
    "# Map v_nom -> color\n",
    "vnom_to_color = dict(zip(uniques, colors))\n",
    "\n",
    "# Optional: export transformers for inspection\n",
    "network.transformers.to_csv(\"ecuador_transformers.csv\", index=False)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# GADM boundary data (expects `country_gadm` to be defined upstream, e.g., \"ECU\")\n",
    "# ---------------------------------------------------------------------\n",
    "GADM_filename = f\"gadm41_{country_gadm}\"\n",
    "GADM_url = f\"https://geodata.ucdavis.edu/gadm/gadm4.1/gpkg/{GADM_filename}.gpkg\"\n",
    "GADM_inputfile_gpkg = os.path.join(os.getcwd(), \"pypsa-earth\", \"data\", \"gadm\", f\"{GADM_filename}.gpkg\")\n",
    "\n",
    "if not Path(GADM_inputfile_gpkg).is_file():\n",
    "    resp = requests.get(GADM_url, stream=True, timeout=300)\n",
    "    resp.raise_for_status()\n",
    "    Path(GADM_inputfile_gpkg).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(GADM_inputfile_gpkg, \"wb\") as f:\n",
    "        shutil.copyfileobj(resp.raw, f)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Plot\n",
    "# ---------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.set_title(\"Buses by Nominal Voltage\")\n",
    "\n",
    "# Admin boundaries\n",
    "adm1 = gpd.read_file(GADM_inputfile_gpkg, layer=\"ADM_ADM_1\")\n",
    "adm1.boundary.plot(ax=ax, linewidth=0.2, color=\"black\")\n",
    "\n",
    "# Line widths proportional to voltage\n",
    "v_to_width = {v: v * 0.004 + 0.5 for v in uniques}\n",
    "\n",
    "network.plot(\n",
    "    ax=ax,\n",
    "    bus_colors=network.buses.v_nom.map(vnom_to_color),\n",
    "    line_colors=network.lines.v_nom.map(vnom_to_color),\n",
    "    line_widths=network.lines.v_nom.map(v_to_width),\n",
    "    bus_sizes=0.01 / 5,\n",
    "    color_geomap=True,\n",
    ")\n",
    "\n",
    "# Legend\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker=\"o\", linestyle=\"none\",\n",
    "               markerfacecolor=vnom_to_color[v], markeredgecolor=\"none\",\n",
    "               markersize=10, label=f\"{v} kV\")\n",
    "    for v in vnom_to_color\n",
    "]\n",
    "ax.legend(\n",
    "    handles=handles,\n",
    "    title=\"Nominal Voltage\",\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.1, 1),\n",
    "    borderaxespad=0,\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef66a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946b38d",
   "metadata": {},
   "source": [
    "#Plotting all the generation points\n",
    "\n",
    "Data was manually prepared from\n",
    " \n",
    "https://www.ambienteyenergia.gob.ec/wp-content/uploads/2020/01/5.-PLAN-DE-EXPANSION-DE-LA-TRANSMISION.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d4224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# === Step 0: Assert the file exists ===\n",
    "generation_path = os.path.join(os.getcwd(), \"documentation\", \"ecuador_data\")\n",
    "generation_file = \"generation_filtered.xlsx\"\n",
    "full_generation_path = os.path.join(generation_path, generation_file)\n",
    "assert os.path.isfile(full_generation_path), f\"‚ùå Generation file not found: {full_generation_path}\"\n",
    "\n",
    "# === Step 1: Load the Excel file ===\n",
    "input_file = full_generation_path\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# === Step 2: Define the new structure ===\n",
    "columns = [\n",
    "    \"Name\", \"Fueltype\", \"Technology\", \"Set\", \"Country\", \"Capacity\",\n",
    "    \"Efficiency\", \"Duration\", \"Volume_Mm3\", \"DamHeight_m\",\n",
    "    \"StorageCapacity_MWh\", \"DateIn\", \"DateRetrofit\", \"DateOut\",\n",
    "    \"lat\", \"lon\", \"EIC\", \"projectID\"\n",
    "]\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# === Step 3: Map available data ===\n",
    "new_df[\"Name\"] = df[\"Central\"]\n",
    "new_df[\"Fueltype\"] = df[\"Tipo de Central\"]\n",
    "new_df[\"Technology\"] = df[\"Subtipo de Central\"]\n",
    "new_df[\"Set\"] = df[\"Sistema\"]\n",
    "new_df[\"Country\"] = \"Ecuador\"\n",
    "new_df[\"Capacity\"] = df[\"Potencia Efectiva (MW)\"]\n",
    "new_df[\"lat\"] = df[\"Latitud\"]\n",
    "new_df[\"lon\"] = df[\"Longitud\"]\n",
    "\n",
    "# === Step 4: Clean strings ===\n",
    "def clean_text(value):\n",
    "    \"\"\"Remove accents, replace spaces with underscores, and handle NaN safely.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    value = str(value)\n",
    "    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('utf-8')\n",
    "    value = value.replace(\" \", \"_\")\n",
    "    return value.strip()\n",
    "\n",
    "for col in new_df.select_dtypes(include=['object']).columns:\n",
    "    new_df[col] = new_df[col].apply(clean_text)\n",
    "\n",
    "# === Step 5: Ensure unique names ===\n",
    "def make_unique(series):\n",
    "    \"\"\"Append _2, _3, etc. to duplicated names.\"\"\"\n",
    "    counts = {}\n",
    "    unique_names = []\n",
    "    for name in series:\n",
    "        if name not in counts:\n",
    "            counts[name] = 1\n",
    "            unique_names.append(name)\n",
    "        else:\n",
    "            counts[name] += 1\n",
    "            unique_names.append(f\"{name}_{counts[name]}\")\n",
    "    return unique_names\n",
    "\n",
    "if new_df[\"Name\"].duplicated().any():\n",
    "    print(\"‚ö†Ô∏è Duplicate names detected ‚Äî renaming...\")\n",
    "    new_df[\"Name\"] = make_unique(new_df[\"Name\"])\n",
    "\n",
    "assert new_df[\"Name\"].is_unique, \"‚ùå Duplicate names still exist after renaming.\"\n",
    "\n",
    "# Temp Date In so they are by default included in the evaluation\n",
    "\n",
    "new_df[\"DateIn\"]= 2000  \n",
    "# === Step 6: Export cleaned file ===\n",
    "ppl_path = os.path.join(os.getcwd(), \"pypsa-earth\", \"data\", \"ppl\", \"EC\")\n",
    "os.makedirs(ppl_path, exist_ok=True)\n",
    "ppl_file = os.path.join(ppl_path, \"powerplants_existing.csv\")\n",
    "\n",
    "new_df.to_csv(ppl_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "import copy\n",
    "ppl_existent = copy.deepcopy(new_df)\n",
    "\n",
    "print(f\"‚úÖ New CSV file created and cleaned: {ppl_file}\")\n",
    "print(f\"‚úÖ All {len(new_df)} plant names are unique.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot Ecuadorian power plants by technology and capacity (English labels).\n",
    "\n",
    "Uses:\n",
    "- Color: Technology type (translated to English)\n",
    "- Bubble size: Capacity (log scale)\n",
    "Requires `new_df` DataFrame with columns:\n",
    "  ['Name', 'Technology', 'Capacity', 'lat', 'lon']\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.cm import get_cmap\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Load generator data\n",
    "# ---------------------------------------------------------------------\n",
    "# Assuming new_df is already defined from the previous script\n",
    "# new_df = pd.read_csv(\"powerplants_temp.csv\")\n",
    "\n",
    "plot_df = new_df.dropna(subset=[\"lat\", \"lon\", \"Capacity\"]).copy()\n",
    "plot_df = plot_df[plot_df[\"Capacity\"].astype(float) > 0]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Translate Technology names (Spanish ‚Üí English)\n",
    "# ---------------------------------------------------------------------\n",
    "tech_translation = {\n",
    "    \"Pasada\": \"Run-of-river hydro\",\n",
    "    \"Embalse\": \"Reservoir hydro\",\n",
    "    \"E√≥lica\": \"Wind\",\n",
    "    \"Eolica\": \"Wind\",\n",
    "    \"Fotovoltaica\": \"Solar PV\",\n",
    "    \"MCI\": \"Internal combustion\",\n",
    "    \"Turbog√°s\": \"Gas turbine\",\n",
    "    \"Turbovapor\": \"Steam turbine\",\n",
    "    \"Biomasa\": \"Biomass\",\n",
    "    \"Biog√°s\": \"Biogas\",\n",
    "}\n",
    "\n",
    "plot_df[\"Technology_Eng\"] = plot_df[\"Technology\"].map(tech_translation).fillna(plot_df[\"Technology\"])\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Load Ecuador boundary (GADM)\n",
    "# ---------------------------------------------------------------------\n",
    "country_gadm = \"ECU\"\n",
    "GADM_filename = f\"gadm41_{country_gadm}.gpkg\"\n",
    "GADM_inputfile_gpkg = os.path.join(\n",
    "    os.getcwd(), \"pypsa-earth\", \"data\", \"gadm\", GADM_filename\n",
    ")\n",
    "assert Path(GADM_inputfile_gpkg).is_file(), f\"GADM file not found: {GADM_inputfile_gpkg}\"\n",
    "\n",
    "ecuador_shape = gpd.read_file(GADM_inputfile_gpkg, layer=\"ADM_ADM_1\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Color map by technology (English)\n",
    "# ---------------------------------------------------------------------\n",
    "technologies = plot_df[\"Technology_Eng\"].unique()\n",
    "n_colors = len(technologies)\n",
    "cmap = get_cmap(\"tab10\") if n_colors <= 10 else get_cmap(\"tab20\")\n",
    "tech_to_color = {tech: cmap(i / n_colors) for i, tech in enumerate(technologies)}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Compute bubble size (log-scaled by capacity)\n",
    "# ---------------------------------------------------------------------\n",
    "cap = plot_df[\"Capacity\"].astype(float)\n",
    "plot_df[\"size\"] = np.log10(cap + 1) * 40  # adjust multiplier if needed\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Plot setup\n",
    "# ---------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.set_title(\"Ecuador Power Plants by Technology\", fontsize=14)\n",
    "\n",
    "# Plot boundaries\n",
    "ecuador_shape.boundary.plot(ax=ax, linewidth=0.4, color=\"black\", alpha=0.7)\n",
    "\n",
    "# Plot generators\n",
    "for tech, group in plot_df.groupby(\"Technology_Eng\"):\n",
    "    ax.scatter(\n",
    "        group[\"lon\"].astype(float),\n",
    "        group[\"lat\"].astype(float),\n",
    "        s=group[\"size\"],\n",
    "        color=tech_to_color[tech],\n",
    "        label=tech,\n",
    "        alpha=0.7,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.3,\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Legend\n",
    "# ---------------------------------------------------------------------\n",
    "ax.legend(\n",
    "    title=\"Technology Type\",\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    borderaxespad=0,\n",
    ")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d992076",
   "metadata": {},
   "source": [
    "# Newer power plants\n",
    "New power plants that according the master plan shall come into operation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff917cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "generation_path = os.path.join(os.getcwd(), \"documentation\", \"ecuador_data\")\n",
    "input_file = os.path.join(generation_path, \"generation_future.xlsx\")\n",
    "assert os.path.isfile(input_file), f\"‚ùå Future generation file not found: {input_file}\"\n",
    "\n",
    "\n",
    "# === Load ===\n",
    "df = pd.read_excel(input_file, sheet_name=\"Future\")\n",
    "\n",
    "# Expected input columns (for clarity):\n",
    "# \"A√±o de entrada en operaci√≥n\",\"Proyecto / Central\",\"Empresa / Instituci√≥n\",\"Estado\",\n",
    "# \"Inversi√≥n p√∫blica o privada\",\"Tipo\",\"Potencia [MW]\",\"Energ√≠a media [GWh/a√±o]\",\n",
    "# \"Provincia\",\"Cant√≥n\",\"Latitud\",\"Longitud\"\n",
    "\n",
    "# === Target structure ===\n",
    "columns = [\n",
    "    \"Name\",\n",
    "    \"Fueltype\",\n",
    "    \"Technology\",\n",
    "    \"Set\",\n",
    "    \"Country\",\n",
    "    \"Capacity\",\n",
    "    \"Efficiency\",\n",
    "    \"Duration\",\n",
    "    \"Volume_Mm3\",\n",
    "    \"DamHeight_m\",\n",
    "    \"StorageCapacity_MWh\",\n",
    "    \"DateIn\",\n",
    "    \"DateRetrofit\",\n",
    "    \"DateOut\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"EIC\",\n",
    "    \"projectID\",\n",
    "]\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# === Map available data ===\n",
    "new_df[\"Name\"] = df[\"Proyecto / Central\"]\n",
    "new_df[\"Fueltype\"] = df[\"Tipo\"]  # keep as provided (normalized below)\n",
    "new_df[\"Technology\"] = \"\"  # not provided in this sheet\n",
    "new_df[\"Set\"] = \"S.N.I.\"  # tag to distinguish dataset\n",
    "new_df[\"Country\"] = \"Ecuador\"\n",
    "new_df[\"Capacity\"] = pd.to_numeric(df[\"Potencia [MW]\"], errors=\"coerce\")\n",
    "new_df[\"DateIn\"] = pd.to_numeric(df[\"A√±o de entrada en operaci√≥n\"], errors=\"coerce\")\n",
    "new_df[\"lat\"] = pd.to_numeric(df[\"Latitud\"], errors=\"coerce\")\n",
    "new_df[\"lon\"] = pd.to_numeric(df[\"Longitud\"], errors=\"coerce\")\n",
    "\n",
    "# Empty optional fields\n",
    "for c in [\n",
    "    \"Efficiency\",\n",
    "    \"Duration\",\n",
    "    \"Volume_Mm3\",\n",
    "    \"DamHeight_m\",\n",
    "    \"StorageCapacity_MWh\",\n",
    "    \"DateRetrofit\",\n",
    "    \"DateOut\",\n",
    "    \"EIC\",\n",
    "    \"projectID\",\n",
    "]:\n",
    "    new_df[c] = np.nan\n",
    "\n",
    "\n",
    "# === String normalization (remove accents, spaces->underscores) ===\n",
    "def clean_text(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    value = str(value)\n",
    "    value = (\n",
    "        unicodedata.normalize(\"NFKD\", value).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    )\n",
    "    value = value.replace(\" \", \"_\")\n",
    "    return value.strip()\n",
    "\n",
    "\n",
    "for col in [\"Name\", \"Fueltype\", \"Technology\", \"Set\", \"Country\", \"EIC\", \"projectID\"]:\n",
    "    new_df[col] = new_df[col].apply(clean_text)\n",
    "\n",
    "\n",
    "# === Ensure unique plant names ===\n",
    "def make_unique(series):\n",
    "    counts = {}\n",
    "    out = []\n",
    "    for name in series:\n",
    "        if name not in counts:\n",
    "            counts[name] = 1\n",
    "            out.append(name)\n",
    "        else:\n",
    "            counts[name] += 1\n",
    "            out.append(f\"{name}_{counts[name]}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "if new_df[\"Name\"].duplicated().any():\n",
    "    print(\"‚ö†Ô∏è Duplicate names detected ‚Äî renaming...\")\n",
    "    # new_df[\"Name\"] = make_unique(new_df[\"Name\"])\n",
    "\n",
    "assert new_df[\"Name\"].is_unique, \"‚ùå Duplicate names still exist after renaming.\"\n",
    "\n",
    "tech = {\n",
    "    \"Hidroelectrico\": \"Embalse\",\n",
    "    \"Termoelectrico\": \"MCI\",\n",
    "    \"Eolico\": \"Eolica\",\n",
    "    \"ERNC\": \"Fotovoltaica\",\n",
    "}\n",
    "\n",
    "for i, row in new_df.iterrows():\n",
    "    new_df.at[i,\"Technology\"] = tech[row[\"Fueltype\"]]\n",
    "\n",
    "# === Export ===\n",
    "\n",
    "# === Step 6: Export cleaned file ===\n",
    "ppl_path = os.path.join(os.getcwd(), \"pypsa-earth\", \"data\", \"ppl\", \"EC\")\n",
    "os.makedirs(ppl_path, exist_ok=True)\n",
    "out_file = os.path.join(ppl_path, \"powerplants_future.csv\")\n",
    "\n",
    "# Use UTF-8 (PyPSA-friendly). If you want Excel-safe accents, use encoding='utf-8-sig'.\n",
    "new_df.to_csv(out_file, index=False, encoding=\"utf-8\")\n",
    "ppl_future = copy.deepcopy(new_df)\n",
    "print(f\"‚úÖ Future CSV created: {out_file}\")\n",
    "print(f\"‚úÖ Rows: {len(new_df)} | Unique names: {new_df['Name'].is_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0b81c",
   "metadata": {},
   "source": [
    "#### Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add powerplants\n",
    "import powerplantmatching as pm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# print default dataset (data from Europe, currently not working)\n",
    "#pm.powerplants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc61135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "ppmatching = os.path.join(\n",
    "    os.getcwd(), \"pypsa-earth\", \"configs\", \"powerplantmatching_config.yaml\"\n",
    ")\n",
    "config = pm.get_config(ppmatching)\n",
    "\n",
    "# Select target countries\n",
    "config[\"target_countries\"] = [\"EC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Define the output path ===\n",
    "ppl_path = os.path.join(os.getcwd(), \"pypsa-earth\", \"data\", \"ppl\", \"EC\")\n",
    "os.makedirs(ppl_path, exist_ok=True)\n",
    "out_file = os.path.join(ppl_path, \"powerplants_all.csv\")\n",
    "\n",
    "# === Step 2: Concatenate vertically ===\n",
    "# (both DataFrames must have the same columns)\n",
    "combined_df = pd.concat([ppl_existent, ppl_future], axis=0, ignore_index=True)\n",
    "\n",
    "# === Step 3: Verify structure ===\n",
    "print(f\"üß© Combined shape: {combined_df.shape}\")\n",
    "print(f\"üìã Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# === Step 4: Export to CSV ===\n",
    "# Use utf-8-sig for Excel compatibility if needed\n",
    "combined_df.to_csv(out_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"‚úÖ Combined power plants file saved at:\\n   {out_file}\")\n",
    "print(f\"‚úÖ Total plants: {len(combined_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "ppl_path = os.path.join(os.getcwd(), \"pypsa-earth\", \"data\", \"ppl\", \"EC\")\n",
    "ppl_file = os.path.join(ppl_path, \"powerplants_all.csv\")\n",
    "\n",
    "\n",
    "\n",
    "if Path(ppl_file).is_file():\n",
    "    ppl = pd.read_csv( ppl_file, index_col=0)\n",
    "    logging.info(f\"Powerplant file found: {ppl_file}, loading existing data.\")\n",
    "\n",
    "else:\n",
    "    #creathe path if ppl_path does not exist\n",
    "    if not os.path.exists(ppl_path):\n",
    "        Path(ppl_path).mkdir(parents=True, exist_ok=True)\n",
    "        logging.info(f\"Created directory for powerplant data: {ppl_path}\")\n",
    "\n",
    "    # include solar and wind\n",
    "    ppl = pm.powerplants(from_url=False, update=True, config_update=config).powerplant.fill_missing_decommissioning_years() \n",
    "    logging.info(f\"Powerplant data loaded and saved to: {ppl_file}\")\n",
    "    # drop renewable power plants\n",
    "\n",
    "    #ppl = pm.powerplants(from_url=False, update=True, config_update=config).powerplant.fill_missing_decommissioning_years().query('Fueltype not in [\"Solar\", \"Wind\"]') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25bb57",
   "metadata": {},
   "source": [
    "#### Information about the Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update ppl to match pypsa network\n",
    "ppl_f = ppl.powerplant.fill_missing_commissioning_years()\n",
    "ppl_p = ppl_f.powerplant.to_pypsa_names()\n",
    "ppl_p = ppl_p.dropna(axis=1, how=\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Power Plants by size and by conection to network\n",
    "ppl_connected = ppl_p[ppl_p['component']==\"S.N.I.\"]  # Keep only plants connected to the network\n",
    "ppl_connected_current = ppl_connected[ppl_connected['DateIn']<=2017]  # Example: filter plants commissioned before or in 2024\n",
    "ppl_connected_future = ppl_connected[ppl_connected['DateIn']>2017]  # Example: filter plants commissioned before or in 2024\n",
    "ppl_filtered = ppl_connected[ppl_connected['p_nom']>=10]  # Example: filter plants with capacity >= 100 kW\n",
    "\n",
    "total_capacity = ppl_p['p_nom'].sum()\n",
    "total_connected = ppl_connected['p_nom'].sum()\n",
    "total_connected_current = ppl_connected_current['p_nom'].sum()\n",
    "total_filtered = ppl_filtered['p_nom'].sum()\n",
    "logging.info(f\"\\nTotal capacity: {total_capacity} kW,\\nConnected capacity: {total_connected} kW, \\\n",
    "             \\nConnected current capacity: {total_connected_current} kW, \\\n",
    "             \\nFiltered capacity: {total_filtered} kW\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9f7a2",
   "metadata": {},
   "source": [
    "#### Attach Powerplants to the Nearest Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree as KDTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose substations (example: low-voltage)\n",
    "substation_i = network.buses.query(\"substation_lv\").index\n",
    "\n",
    "# Build KDTree on bus coordinates\n",
    "kdtree = KDTree(network.buses.loc[substation_i, [\"x\", \"y\"]].values)\n",
    "\n",
    "# Match plants to nearest bus\n",
    "tree_i = kdtree.query(ppl_filtered[[\"lon\", \"lat\"]].values)[1]\n",
    "ppl_filtered[\"bus\"] = substation_i[tree_i].values\n",
    "ppl_filtered.head()\n",
    "ppl_filtered.to_csv(\"power_plants_all_mapped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb3d20",
   "metadata": {},
   "source": [
    "#### Printing of Total Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7218562",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_carriers_es = (\n",
    "    ppl_p[\"carrier\"]\n",
    "    .astype(str).str.strip().str.lower()\n",
    "    .dropna().unique()\n",
    ")\n",
    "unique_carriers_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23baa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Find unique carriers (Spanish)\n",
    "unique_carriers_es = (\n",
    "    ppl_p[\"carrier\"]\n",
    "    .astype(str).str.strip().str.lower()\n",
    "    .dropna().unique()\n",
    ")\n",
    "\n",
    "# 2) Translate to English\n",
    "carrier_map_es2en = {\n",
    "    \"hidraulica\": \"Hydro\",\n",
    "    \"hidr√°ulica\": \"Hydro\",\n",
    "    \"hidroelectrico\": \"Hydro\",\n",
    "    \"termica\": \"Thermal\",\n",
    "    \"t√©rmica\": \"Thermal\",\n",
    "    \"termoelectrico\": \"Thermal\",\n",
    "    \"biomasa\": \"Biomass\",\n",
    "    \"fotovoltaica\": \"Solar PV\",\n",
    "    \"eolica\": \"Wind\",\n",
    "    \"e√≥lica\": \"Wind\",\n",
    "    \"eolico\": \"Wind\",\n",
    "    \"biogas\": \"Biogas\",\n",
    "    \"biog√°s\": \"Biogas\",\n",
    "    \"ernc\": \"Other ER\",\n",
    "}\n",
    "\n",
    "# Normalise and map; fall back to title-cased original if not in mapping\n",
    "ppl_p[\"carrier_norm\"] = ppl_p[\"carrier\"].astype(str).str.strip().str.lower()\n",
    "ppl_p[\"carrier_en\"] = ppl_p[\"carrier_norm\"].map(carrier_map_es2en).fillna(\n",
    "    ppl_p[\"carrier\"].astype(str).str.strip().str.title()\n",
    ")\n",
    "\n",
    "# Ensure capacity numeric (handles things like \"1'500,00\")\n",
    "ppl_p[\"p_nom\"] = (\n",
    "    ppl_p[\"p_nom\"].astype(str)\n",
    "    .str.replace(\"'\", \"\", regex=False)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    ")\n",
    "ppl_p[\"p_nom\"] = pd.to_numeric(ppl_p[\"p_nom\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# Aggregate by translated carrier\n",
    "capacity_by_carrier = (\n",
    "    ppl_p.groupby(\"carrier_en\")[\"p_nom\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "total_capacity = capacity_by_carrier.sum()\n",
    "\n",
    "# Plot\n",
    "colors = plt.cm.tab20.colors[:len(capacity_by_carrier)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(capacity_by_carrier.index, capacity_by_carrier.values, color=colors)\n",
    "\n",
    "# Labels with MW and %\n",
    "for bar, val in zip(bars, capacity_by_carrier.values):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.01 * capacity_by_carrier.max(),\n",
    "        f\"{val:.0f} MW\\n({(val / total_capacity * 100):.1f}%)\",\n",
    "        ha=\"center\", va=\"bottom\", fontsize=10\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Installed Capacity (MW)\")\n",
    "plt.xlabel(\"Fuel Type\")\n",
    "plt.title(\"Total Installed Capacity by Fuel Type in Ecuador\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7c4f1",
   "metadata": {},
   "source": [
    "#### Buses and Powerplants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08817121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define Coordinate Reference Systems (CRS)\n",
    "geo_crs = 4326  # general geographic projection, not used for metric measures. \"EPSG:4326\" is the standard used by OSM and google maps\n",
    "area_crs = 6933 # projection for area measurements only. Possible recommended values are Global Mollweide \"ESRI:54009\" (but 54009 is not supported by atlite, use 6933 instead)\n",
    "# distance_crs = 3857  # projection for distance measurements only. Possible recommended values are \"EPSG:3857\" (used by OSM and Google Maps) -> currently not used\n",
    "\n",
    "# Read coordinates from powerplants and buses\n",
    "ppl_geometry = gpd.points_from_xy(ppl_filtered['lon'], ppl_filtered['lat'])\n",
    "buses_geometry = gpd.points_from_xy(network.buses['lon'], network.buses['lat'])\n",
    "ppl_capacities =gpd.GeoDataFrame(ppl_filtered, geometry=ppl_geometry, crs=geo_crs)\n",
    "buses_capacities =gpd.GeoDataFrame(network.buses, geometry=buses_geometry, crs=geo_crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934fe2d",
   "metadata": {},
   "source": [
    "#### Attach Powerplants to the Nearest Bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e10d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree as KDTree\n",
    "import numpy as np\n",
    "\n",
    "substation_i = network.buses.query(\"substation_lv\").index\n",
    "kdtree = KDTree(network.buses.loc[substation_i, [\"x\", \"y\"]].values)\n",
    "ppl_i = ppl_filtered.index\n",
    "\n",
    "tree_i = kdtree.query(ppl_filtered.loc[ppl_i, [\"lon\", \"lat\"]].values)[1]\n",
    "ppl_filtered.loc[ppl_i, \"bus\"] = substation_i.append(pd.Index([np.nan]))[tree_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f222b",
   "metadata": {},
   "source": [
    "#### Add Powerplants to the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.madd(\"Generator\", \n",
    "             ppl_filtered.index, bus=ppl_filtered.bus,\n",
    "               p_nom=ppl_filtered.p_nom, carrier=ppl_filtered.carrier)\n",
    "\n",
    "network.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a493614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the time horizon\n",
    "years = range(2025, 2050)\n",
    "\n",
    "# Build a dataframe with capacity per carrier per year\n",
    "capacity_by_year_carrier = pd.DataFrame(index=years)\n",
    "\n",
    "for year in years:\n",
    "    # Plants active at this year\n",
    "    active_ppl = ppl[(ppl[\"DateIn\"].isna()) | (ppl[\"DateIn\"] <= year)]\n",
    "    # Sum capacity by carrier\n",
    "    capacity_by_carrier = active_ppl.groupby(\"carrier\")[\"p_nom\"].sum()\n",
    "    capacity_by_year_carrier.loc[year, capacity_by_carrier.index] = capacity_by_carrier.values\n",
    "\n",
    "# Replace NaNs with 0\n",
    "capacity_by_year_carrier = capacity_by_year_carrier.fillna(0)\n",
    "\n",
    "# Order carriers by their final capacity in 2040\n",
    "order = capacity_by_year_carrier.loc[2040].sort_values().index\n",
    "capacity_by_year_carrier = capacity_by_year_carrier[order]\n",
    "\n",
    "# Plot as stacked area\n",
    "plt.figure(figsize=(12,7))\n",
    "capacity_by_year_carrier.plot.area(ax=plt.gca(), alpha=0.85)\n",
    "\n",
    "plt.title(\"Installed Capacity in Ghana by Carrier (2025‚Äì2040)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Installed Capacity (MW)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend(title=\"Carrier\", loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Export generators to Excel\n",
    "output_file = \"network_generators.xlsx\"\n",
    "network.generators.to_excel(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Sample Data ---\n",
    "# Note: The original code relied on 'ppl' data, which was not provided.\n",
    "# This sample data simulates a dataframe with installed power plant capacity\n",
    "# to make the script runnable and demonstrate the interpolation.\n",
    "ppl = pd.DataFrame({\n",
    "    \"carrier\": [\n",
    "        \"solar\", \"solar\", \"solar\", \"natural_gas\", \"natural_gas\",\n",
    "        \"nuclear\", \"hydro\", \"oil\"\n",
    "    ],\n",
    "    \"p_nom\": [\n",
    "        300, 450, 275, 5500, 3000,\n",
    "        200, 1000, 500\n",
    "    ],\n",
    "    \"DateIn\": [\n",
    "        2025, 2026, 2028, 2025, 2027,\n",
    "        2028, None, 2029\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Define the time horizon\n",
    "years = range(2025, 2041)\n",
    "\n",
    "# Build a dataframe with capacity per carrier per year, with a base case up to 2030\n",
    "capacity_by_year_carrier = pd.DataFrame(index=years)\n",
    "\n",
    "for year in years:\n",
    "    # Plants active up to this year, excluding the interpolated carriers\n",
    "    active_ppl = ppl[(ppl[\"DateIn\"].isna()) | (ppl[\"DateIn\"] <= year)]\n",
    "    # Sum capacity for all carriers\n",
    "    capacity_by_carrier = active_ppl.groupby(\"carrier\")[\"p_nom\"].sum()\n",
    "    capacity_by_year_carrier.loc[year, capacity_by_carrier.index] = capacity_by_carrier.values\n",
    "\n",
    "# Replace NaNs with 0\n",
    "capacity_by_year_carrier = capacity_by_year_carrier.fillna(0)\n",
    "\n",
    "# --- Interpolation Logic ---\n",
    "# The user-provided values for 2035 and 2040\n",
    "interpolated_carriers = ['solar', 'natural_gas', 'nuclear']\n",
    "target_values = {\n",
    "    2035: {'solar': 1020, 'natural_gas': 11050, 'nuclear': 600},\n",
    "    2040: {'solar': 1665, 'natural_gas': 14650, 'nuclear': 1200}\n",
    "}\n",
    "\n",
    "# Create a temporary DataFrame for interpolation\n",
    "interp_data = pd.DataFrame(index=years)\n",
    "\n",
    "for carrier in interpolated_carriers:\n",
    "    # Get the value at 2030 from the initial data\n",
    "    base_value = capacity_by_year_carrier.loc[2030, carrier]\n",
    "    \n",
    "    # Set up the series with known values for interpolation\n",
    "    values = pd.Series(index=years, dtype=float)\n",
    "    values.loc[2030] = base_value\n",
    "    values.loc[2035] = target_values[2035][carrier]\n",
    "    values.loc[2040] = target_values[2040][carrier]\n",
    "    \n",
    "    # Linearly interpolate the values between 2030 and 2040\n",
    "    interp_values = values.interpolate(method='linear', limit_direction='forward')\n",
    "    \n",
    "    # Fill the temporary DataFrame\n",
    "    interp_data[carrier] = interp_values\n",
    "\n",
    "# Merge the interpolated data back into the main DataFrame\n",
    "# First, fill the years 2031-2040 for the interpolated carriers with NaNs\n",
    "# to ensure they are replaced by the interpolated values\n",
    "capacity_by_year_carrier.loc[2031:2040, interpolated_carriers] = np.nan\n",
    "capacity_by_year_carrier.update(interp_data)\n",
    "\n",
    "# Re-order carriers for consistent plotting\n",
    "order = capacity_by_year_carrier.loc[2040].sort_values().index\n",
    "capacity_by_year_carrier = capacity_by_year_carrier[order]\n",
    "\n",
    "# Plot as stacked area\n",
    "plt.figure(figsize=(12,7))\n",
    "capacity_by_year_carrier.plot.area(ax=plt.gca(), alpha=0.85)\n",
    "\n",
    "plt.title(\"Installed Capacity in Ghana by Carrier (2025‚Äì2040)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Installed Capacity (MW)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend(title=\"Carrier\", loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Sample Data ---\n",
    "ppl = pd.DataFrame({\n",
    "    \"carrier\": [\n",
    "        \"solar\", \"solar\", \"solar\", \"natural_gas\", \"natural_gas\",\n",
    "        \"nuclear\", \"hydro\", \"oil\"\n",
    "    ],\n",
    "    \"p_nom\": [\n",
    "        300, 450, 275, 5500, 3000,\n",
    "        200, 1000, 500\n",
    "    ],\n",
    "    \"DateIn\": [\n",
    "        2025, 2026, 2028, 2025, 2027,\n",
    "        2028, None, 2029\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Define the time horizon\n",
    "years = range(2025, 2041)\n",
    "\n",
    "# Build a dataframe with capacity per carrier per year, with a base case up to 2030\n",
    "capacity_by_year_carrier = pd.DataFrame(index=years)\n",
    "\n",
    "for year in years:\n",
    "    active_ppl = ppl[(ppl[\"DateIn\"].isna()) | (ppl[\"DateIn\"] <= year)]\n",
    "    capacity_by_carrier = active_ppl.groupby(\"carrier\")[\"p_nom\"].sum()\n",
    "    capacity_by_year_carrier.loc[year, capacity_by_carrier.index] = capacity_by_carrier.values\n",
    "\n",
    "capacity_by_year_carrier = capacity_by_year_carrier.fillna(0)\n",
    "\n",
    "# --- Interpolation Logic ---\n",
    "interpolated_carriers = ['solar', 'natural_gas', 'nuclear']\n",
    "target_values = {\n",
    "    2035: {'solar': 1020, 'natural_gas': 11050, 'nuclear': 600},\n",
    "    2040: {'solar': 1665, 'natural_gas': 14650, 'nuclear': 1200}\n",
    "}\n",
    "\n",
    "interp_data = pd.DataFrame(index=years)\n",
    "for carrier in interpolated_carriers:\n",
    "    base_value = capacity_by_year_carrier.loc[2030, carrier]\n",
    "    values = pd.Series(index=years, dtype=float)\n",
    "    values.loc[2030] = base_value\n",
    "    values.loc[2035] = target_values[2035][carrier]\n",
    "    values.loc[2040] = target_values[2040][carrier]\n",
    "    interp_values = values.interpolate(method='linear', limit_direction='forward')\n",
    "    interp_data[carrier] = interp_values\n",
    "\n",
    "capacity_by_year_carrier.loc[2031:2040, interpolated_carriers] = np.nan\n",
    "capacity_by_year_carrier.update(interp_data)\n",
    "\n",
    "# Re-order carriers\n",
    "order = capacity_by_year_carrier.loc[2040].sort_values().index\n",
    "capacity_by_year_carrier = capacity_by_year_carrier[order]\n",
    "\n",
    "# --- CAPEX values ---\n",
    "capex_data = {\n",
    "    2030: {'nuclear': 2790000000, 'natural_gas': 2621700000, 'solar': 582750000},\n",
    "    2040: {'nuclear': 8370000000, 'natural_gas': 7339500000, 'solar': 992250000}\n",
    "}\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(12,7))\n",
    "ax = capacity_by_year_carrier.plot.area(ax=plt.gca(), alpha=0.85)\n",
    "\n",
    "plt.title(\"Installed Capacity in Ghana by Carrier (2025‚Äì2040)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Installed Capacity (MW)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend(title=\"Carrier\", loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "\n",
    "# Add CAPEX annotations\n",
    "for year, carriers in capex_data.items():\n",
    "    for carrier, capex in carriers.items():\n",
    "        y_val = capacity_by_year_carrier.loc[year, carrier]\n",
    "        if y_val > 0:  # annotate only if capacity exists\n",
    "            ax.annotate(\n",
    "                f\"${capex/1e9:.2f}B\",  # format in billions\n",
    "                xy=(year, y_val),\n",
    "                xytext=(year, y_val + 1000),\n",
    "                ha=\"center\",\n",
    "                fontsize=12,  # üîπ bigger text\n",
    "                fontweight=\"bold\",  # üîπ bold text\n",
    "                arrowprops=dict(arrowstyle=\"->\", color=\"black\", lw=1.2)  # thicker arrow\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c919f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cost data\n",
    "filename = 'resources/' + country_code + '/costs_nuclear.csv' # The CSV file has been created with PyPSA-Earth\n",
    "\n",
    "#TODO: Calculate annuity for capital cost, check marginal cost with variable maintenance\n",
    "costs = pd.read_csv(filename, index_col=0)\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators.drop(['marginal_cost', 'capital_cost'], axis=1, inplace=True)\n",
    "\n",
    "# Add cost data from 'costs' to 'network.generators'\n",
    "network.generators = pd.merge(network.generators, costs, left_on='carrier', right_index=True)\n",
    "network.generators[['bus', 'p_nom', 'carrier', 'marginal_cost', 'capital_cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function to calculate the demand profile\n",
    "# Hourly demand profile per bus\n",
    "load_profile_file = 'resources/' + country_code + '/demand_profiles.csv' # The CSV file has been created with PyPSA-Earth\n",
    "load_profile = pd.read_csv(load_profile_file, index_col=0, parse_dates=True)\n",
    "\n",
    "# The peak load for Colombia is less than the installed hydropower capacity, let's increase it by 40%\n",
    "if country_code == 'CO':\n",
    "    load_factor = 1.4\n",
    "else:\n",
    "    load_factor = 1\n",
    "load_profile = load_profile * load_factor\n",
    "load_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5277a",
   "metadata": {},
   "source": [
    "#### Ghana Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the load profile to the network\n",
    "network.madd('Load', load_profile.columns, bus=load_profile.columns, p_set=load_profile)\n",
    "network.loads_t.p_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2fa1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check peak load (rounded to 1 decimal place)\n",
    "print('Peak load: ', round(network.loads_t.p_set.T.sum().max() / 1000, 1), 'GW') # GW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec36d17",
   "metadata": {},
   "source": [
    "#### Region Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_by_region(region_node):\n",
    "    \"\"\"Consider each region as a node.\n",
    "    The centroid of the polygon for regions is the position of the node.\n",
    "\n",
    "    Important:\n",
    "    The projection of the maps is ``EPSG:4674 (SIRGAS 2000) <https://epsg.io/4674>``, unit- degree, geographic CRS.\n",
    "    To use calculations, e.g, \"centroid\", \"sjoin\",  the map needs to be reprojected, ``.to_crs('epsg:4087')``\n",
    "\n",
    "    EPSG:4326 is also a geographic CRS, unit - degree,\n",
    "    # issue: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
    "    # previous: to_crs('epsg:4326'), now: set .to_crs('epsg:4087') solved: see https://gis.stackexchange.com/questions/372564/userwarning-when-trying-to-get-centroid-from-a-polygon-geopandas\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    region_node['x'] = region_node.centroid.x\n",
    "    region_node['y'] = region_node.centroid.y\n",
    "    return region_node\n",
    "\n",
    "region_node = get_node_by_region(shapefile)\n",
    "region_node.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Attach node to region\n",
    "def attach_node_to_region(gdf, longitude, latitude):\n",
    "    # Define the point (longitude, latitude)\n",
    "    point = Point(longitude, latitude)\n",
    "    # Ensure the CRS of GeoDataFrame and point match\n",
    "    if gdf.crs != 'EPSG:4326': # Assuming the point is in WGS84 (EPSG:4326)\n",
    "        gdf = gdf.to_crs('EPSG:4326')\n",
    "    # Find the polygon that contains the point and get the coordinates of the centroid\n",
    "    region = gdf[gdf.contains(point)]['NAME_1'].values[0]\n",
    "    region_x = gdf[gdf.contains(point)]['x'].values[0]\n",
    "    region_y = gdf[gdf.contains(point)]['y'].values[0]\n",
    "    return region, region_x, region_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach region to buses using the attach_node_to_region function\n",
    "def attach_region_to_buses(gdf, buses):\n",
    "    buses['region'] = 'NA'\n",
    "    for i in buses.index:\n",
    "        lon = buses.loc[i]['lon']\n",
    "        lat = buses.loc[i]['lat']\n",
    "        try:\n",
    "            region, region_x, region_y = attach_node_to_region(gdf, lon, lat)\n",
    "        except Exception as e:\n",
    "            print('Error:', e)\n",
    "            print('Index:', i)\n",
    "            continue\n",
    "        buses.loc[i, 'region'] = region\n",
    "        buses.loc[i, 'region_x'] = region_x\n",
    "        buses.loc[i, 'region_y'] = region_y\n",
    "    return buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e736bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create busmap\n",
    "busmap = attach_region_to_buses(region_node, network.buses)['region']\n",
    "busmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lines = network.lines.reindex(columns=network.components['Line']['attrs'].index[1:])\n",
    "network.lines['type'] = np.nan\n",
    "network.buses = network.buses.reindex(columns=network.components['Bus']['attrs'].index[1:])\n",
    "network.buses['frequency'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ac21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the network based on the busmap\n",
    "from pypsa.clustering.spatial import get_clustering_from_busmap\n",
    "clustered = get_clustering_from_busmap(network, busmap).network\n",
    "clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the generators\n",
    "clustered.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered.buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered.lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41166b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlite\n",
    "\n",
    "# Load the cutout\n",
    "cutout_file = 'cutouts/' + country_code + '/cutout-2013-era5.nc'\n",
    "cutout = atlite.Cutout(cutout_file)\n",
    "cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab61258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Calculate the wind and influx \n",
    "wnd100m = cutout.data.wnd100m.mean(dim=\"time\")\n",
    "influx = cutout.data['influx_direct'].mean(dim=\"time\") + cutout.data['influx_diffuse'].mean(dim=\"time\")\n",
    "\n",
    "# Get the total bounds of the shapefile\n",
    "minx, miny, maxx, maxy = shapefile.total_bounds\n",
    "\n",
    "# Plot the wind and influx\n",
    "# TODO: check the units and print them on the legend\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, ax = plt.subplots(1, 2, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(15, 7))\n",
    "\n",
    "# Set titles for each subplot\n",
    "# TODO: titles not visible\n",
    "ax[0].set_title(\"Mean Wind Potential in m/s\", fontsize=14, pad=20)\n",
    "ax[0].set_extent([minx, maxx, miny, maxy], crs=ccrs.PlateCarree())\n",
    "ax[1].set_title(\"Mean Influx in W/m2\", fontsize=14)\n",
    "ax[1].set_extent([minx, maxx, miny, maxy], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Plot data on the first subplot\n",
    "wnd100m.plot(ax=ax[0], cmap=\"Blues\")\n",
    "shapefile.to_crs(geo_crs).plot(ax=ax[0], edgecolor=\"k\", color=\"none\")\n",
    "\n",
    "# Plot data on the second subplot\n",
    "influx.plot(ax=ax[1], cmap=\"Reds\")\n",
    "shapefile.to_crs(geo_crs).plot(ax=ax[1], edgecolor=\"k\", color=\"none\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Adjust the space around the titles if necessary\n",
    "#plt.subplots_adjust(top=5)  # Adjust the value if needed\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508640b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Calculate the area of each cell in the cutout\n",
    "area = cutout.grid.to_crs(area_crs).area / 1e6\n",
    "area = xr.DataArray(area.values.reshape(cutout.shape), [cutout.coords[\"y\"], cutout.coords[\"x\"]])\n",
    "\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfee347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define renewable resources\n",
    "resources = [\n",
    "    {'method': 'wind', 'turbine': 'Vestas_V112_3MW', 'capacity_per_sqkm': 4.6, 'resource': 'onwind'},\n",
    "    {'method': 'pv', 'panel': 'CSi', 'orientation': 'latitude_optimal', 'capacity_per_sqkm': 2, 'resource': 'solar'},\n",
    "]\n",
    "correction_factor = 1\n",
    "\n",
    "# Create new geodataframe for the capacities\n",
    "capacities = shapefile\n",
    "datasets = {}\n",
    "shape = shapefile.set_index(\"NAME_1\")\n",
    "\n",
    "# Calculate capacities per resource\n",
    "# TODO: check the algorithm for correctness and efficiency\n",
    "for resource in resources:\n",
    "    method =  resource['method']\n",
    "    res = resource['resource']\n",
    "    profile_path = 'resources/' + country_code + '/renewable_profiles/profile_' + res + '.nc'\n",
    "    if Path(profile_path).is_file():\n",
    "        print('Profile found:', res)\n",
    "        ds = xr.open_dataset(profile_path)\n",
    "        profile = ds['profile']\n",
    "        capacity = ds['capacities']\n",
    "        capacities[method] = capacity\n",
    "        datasets[res] = ds\n",
    "    else:\n",
    "        print('Profile not found:', res)\n",
    "        cap_per_sqkm = resource['capacity_per_sqkm']\n",
    "        print(method)\n",
    "        params = [resource.pop(key) for key in ['method', 'capacity_per_sqkm', 'resource']][0]\n",
    "        print(resource)\n",
    "        func = getattr(cutout, params)\n",
    "        capacity_factor = correction_factor * func(capacity_factor=True, **resource)\n",
    "        #print(capacity_factor)\n",
    "        layout = capacity_factor * area * cap_per_sqkm\n",
    "        #print(layout)\n",
    "        profile, capacity = func(shapes=shape, per_unit=True, return_capacity=True, layout=layout, **resource)\n",
    "        #print(capacity)\n",
    "        capacities[method] = capacity\n",
    "        ds = xr.Dataset({\n",
    "        'profile': profile.rename({'NAME_1': 'bus'}),\n",
    "        'capacities': capacity.rename({'NAME_1': 'bus'})\n",
    "        })\n",
    "        datasets[res] = ds\n",
    "        ds.to_netcdf(profile_path)\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities['area'] = capacities.to_crs(area_crs).area / 1e6 # convert to km2\n",
    "capacities['area'] = capacities['area'].round(1)\n",
    "capacities['wind'] = capacities['wind'].round(1)\n",
    "capacities['pv'] = capacities['pv'].round(1)\n",
    "capacities['wind_per_sqkm'] = capacities['wind'] / capacities['area']\n",
    "capacities['pv_per_sqkm'] = capacities['pv'] / capacities['area']\n",
    "capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26918752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind and solar potential in subplots\n",
    "# TODO: check units\n",
    "ncols = 3\n",
    "nrows = 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, subplot_kw={'projection': ccrs.PlateCarree()}, figsize=(20, 15))\n",
    "\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax[i, j].set_extent([minx, maxx, miny, maxy], ccrs.PlateCarree())\n",
    "\n",
    "capacities.plot(ax=ax[0, 0], column=\"wind\", legend=True, cmap=\"Blues\", )\n",
    "ax[0,0].set_title(\"Wind Potential in MW\")\n",
    "capacities.apply(lambda x: ax[0,0].annotate(text=x['NAME_1'], xy=x.geometry.centroid.coords[0], fontsize=10, ha='center'), axis=1)\n",
    "capacities.plot(ax=ax[0, 1], column=\"wind_per_sqkm\", legend=True, cmap=\"Blues\")\n",
    "capacities.apply(lambda x: ax[0,1].annotate(text=x['NAME_1'], xy=x.geometry.centroid.coords[0], fontsize=10, ha='center'), axis=1)\n",
    "ax[0,1].set_title('Wind Potential in MW per km¬≤')\n",
    "wnd100m.plot(ax=ax[0, 2], cmap=\"Blues\")\n",
    "ax[0,2].set_title(\"Wind Resource in W/m¬≤\")\n",
    "shapefile.to_crs(geo_crs).plot(ax=ax[0, 2], edgecolor=\"k\", color=\"none\")\n",
    "\n",
    "# PV\n",
    "capacities.plot(ax=ax[1, 0], column=\"pv\", legend=True, cmap=\"Reds\")\n",
    "ax[1,0].set_title(\"PV Potential in MW\")\n",
    "capacities.apply(lambda x: ax[1,0].annotate(text=x['NAME_1'], xy=x.geometry.centroid.coords[0], fontsize=10, ha='center'), axis=1)\n",
    "capacities.plot(ax=ax[1, 1], column=\"pv_per_sqkm\", legend=True, cmap=\"Reds\")\n",
    "ax[1,1].set_title('PV Potential in MW per km¬≤')\n",
    "capacities.apply(lambda x: ax[1,1].annotate(text=x['NAME_1'], xy=x.geometry.centroid.coords[0], fontsize=10, ha='center'), axis=1)\n",
    "influx.plot(ax=ax[1, 2], cmap=\"Reds\")\n",
    "ax[1,2].set_title(\"Solar Resource in W/m¬≤\")\n",
    "shapefile.to_crs(geo_crs).plot(ax=ax[1, 2], edgecolor=\"k\", color=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the emissions data\n",
    "carriers = pd.read_csv('resources/' + country_code + '/carriers.csv', index_col=0).reset_index()\n",
    "\n",
    "# Combine CCGT and OCGT to Natural Gas\n",
    "carriers.loc[carriers.Carrier == 'OCGT', 'Carrier'] = 'natural gas'\n",
    "carriers.loc[carriers.nice_name == 'Open-Cycle Gas', 'nice_name'] = 'Natural Gas'\n",
    "carriers = carriers[carriers.Carrier != 'CCGT']\n",
    "\n",
    "# Set the index to the carrier name\n",
    "carriers.set_index('Carrier', inplace=True)\n",
    "\n",
    "# Add carriers to the network\n",
    "clustered.carriers = carriers\n",
    "clustered.carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a093fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new network with renewables\n",
    "clustered_re = clustered.copy()\n",
    "\n",
    "# Iterate over the datasets in the dictionary to access keys and values\n",
    "for key, ds in datasets.items():\n",
    "    tech = key\n",
    "    # Filter out non-existing buses\n",
    "    # TODO: Check why there is a 'NA' bus in Colombia\n",
    "    try:\n",
    "        ds = ds.sel(bus=clustered.buses.index.drop('NA')) # Drop 'NA' because it creates an error\n",
    "    except:\n",
    "        ds = ds.sel(bus=clustered.buses.index)\n",
    "    # Add renewable generators\n",
    "    clustered_re.madd(\n",
    "        \"Generator\",\n",
    "        ds.indexes[\"bus\"],\n",
    "        \" \" + tech,\n",
    "        bus=ds.indexes[\"bus\"],\n",
    "        carrier=tech,\n",
    "        p_nom=0,\n",
    "        p_nom_extendable=True,\n",
    "        p_nom_min=0,\n",
    "        p_nom_max=ds[\"capacities\"].to_pandas(),\n",
    "        p_max_pu=ds[\"profile\"].transpose(\"time\", \"bus\").to_pandas(),\n",
    "        marginal_cost=costs.at[tech, \"marginal_cost\"],\n",
    "        capital_cost=costs.at[tech, \"capital_cost\"],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706dc5af",
   "metadata": {},
   "source": [
    "#### Solve Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the old network\n",
    "clustered.lines['x'] = 0.1\n",
    "clustered.lines['r'] = 0.01\n",
    "solver = 'gurobi'\n",
    "clustered.optimize()#solver_name=solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bf8cf",
   "metadata": {},
   "source": [
    "#### Example: New Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 2) Current sector shares you provided (use these to estimate current MW by sector)\n",
    "current_shares = {\n",
    "    \"Industry\": 0.32,\n",
    "    \"Residential\": 0.47,\n",
    "    \"Transport\": 0.0003,\n",
    "    \"Agriculture\": 0.0003,\n",
    "    \"Service\": 0.212\n",
    "}\n",
    "\n",
    "current_capacity = {s: share * total_energy for s, share in current_shares.items()}\n",
    "\n",
    "# 3) 2040 target total capacity (MW)\n",
    "target_total_mwh = total_energy2040 \n",
    "\n",
    "# User-provided target shares (note: they sum to 106%)\n",
    "raw_target_shares = {\n",
    "    \"Industry\": 0.48,\n",
    "    \"Residential\": 0.40,\n",
    "    \"Transport\": 0.01,\n",
    "    \"Agriculture\": 0.01,\n",
    "    \"Service\": 0.16\n",
    "}\n",
    "\n",
    "raw_sum = sum(raw_target_shares.values())\n",
    "print(f\"Sum of raw target shares: {raw_sum*100:.2f}%\")\n",
    "\n",
    "# Normalize target shares so they sum to 1.0 (100%)\n",
    "target_shares = {s: v / raw_sum for s, v in raw_target_shares.items()}\n",
    "\n",
    "print(\"Normalized target shares (used to compute MWh):\")\n",
    "for s, v in target_shares.items():\n",
    "    print(f\"  {s}: {v*100:.2f}%\")\n",
    "\n",
    "target_capacity = {s: share * target_total_mwh for s, share in target_shares.items()}\n",
    "\n",
    "# 5) Compute required additions (MW)\n",
    "additional_capacity = {s: max(target_capacity[s] - current_capacity.get(s, 0.0), 0.0) for s in target_capacity}\n",
    "\n",
    "# Prepare a DataFrame summary for neat printing / plotting\n",
    "df = pd.DataFrame({\n",
    "    \"current_mwh\": pd.Series(current_capacity),\n",
    "    \"target_mwh\": pd.Series(target_capacity),\n",
    "    \"additional_mwh\": pd.Series(additional_capacity),\n",
    "    \"current_share_%\": pd.Series(current_shares).mul(100),\n",
    "    \"target_share_%\": pd.Series(target_shares).mul(100)\n",
    "}).fillna(0.0)\n",
    "\n",
    "print(\"\\nSummary (MWh and shares):\")\n",
    "print(df.round(2))\n",
    "\n",
    "# 6) Plot grouped bar chart: current vs 2040 target per sector\n",
    "sectors = df.index.tolist()\n",
    "x = np.arange(len(sectors))\n",
    "width = 0.35\n",
    "\n",
    "colors = plt.cm.Set2.colors  # palette with distinct colors\n",
    "sector_colors = colors[:len(sectors)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,6))\n",
    "bars_curr = ax.bar(x - width/2, df[\"current_mwh\"].values, width, label=\"Current (MWh)\", color=sector_colors, alpha=0.9)\n",
    "bars_targ = ax.bar(x + width/2, df[\"target_mwh\"].values, width, label=\"Target 2040 (MWh)\", color=sector_colors, alpha=0.45, hatch='//')\n",
    "\n",
    "# Add labels above each bar: MW and share%\n",
    "def autolabel(bars, values_share_pct):\n",
    "    for bar, share in zip(bars, values_share_pct):\n",
    "        yval = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2,\n",
    "            yval + 0.01 * max(df[\"target_mwh\"].max(), df[\"current_mwh\"].max()),\n",
    "            f\"{yval:,.0f} MWh\\n({share:.1f}%)\",\n",
    "            ha='center', va='bottom', fontsize=9\n",
    "        )\n",
    "\n",
    "# Current labels use current_share_%, target labels use target_share_%\n",
    "autolabel(bars_curr, df[\"current_share_%\"].values)\n",
    "autolabel(bars_targ, df[\"target_share_%\"].values)\n",
    "\n",
    "ax.set_ylabel(\"Energy (MWh)\")\n",
    "ax.set_title(\"Current vs Target (2040) Energy by Sector\\nTarget total (normalized shares)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sectors, rotation=25, ha=\"right\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
