{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf1720a",
   "metadata": {},
   "source": [
    "## Evaluation of Generators for future Energy Scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ef2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup environment and load the base PyPSA-Earth network for a specified country.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pypsa\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import shutil\n",
    "import pypsa\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap, to_hex\n",
    "# Import all dirs\n",
    "parent_dir = Path(os.getcwd()).parents[0]\n",
    "sys.path.append(str(parent_dir))\n",
    "from src.paths import all_dirs\n",
    "dirs = all_dirs()\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "# Define country parameters\n",
    "country_code = \"EC\"        # ISO 2-letter code (e.g., 'GH' for Ghana, 'CO' for Colombia)\n",
    "country_name = \"Ecuador\"   # Country name\n",
    "country_gadm = \"ECU\"       # ISO 3-letter GADM code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946b38d",
   "metadata": {},
   "source": [
    "#Processing and Plotting all the Generation Points\n",
    "\n",
    "Data was manually prepared from\n",
    " \n",
    "https://www.ambienteyenergia.gob.ec/wp-content/uploads/2020/01/5.-PLAN-DE-EXPANSION-DE-LA-TRANSMISION.pdf\n",
    "\n",
    "The Generation needs to be listed and mapped to the different buses of the network to be ready for coupling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d4224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Duplicate names detected ‚Äî renaming...\n",
      "‚úÖ New CSV file created and cleaned: c:\\Repositories\\Repos\\pypsa-earth-project\\EcuadorElectricGrid\\data\\processed\\generation\\powerplants_existing.csv\n",
      "‚úÖ All 317 plant names are unique.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# === Step 0: Assert the file exists ===\n",
    "generation_path = dirs[\"data/raw/generation\"]\n",
    "generation_file = \"generation_filtered.xlsx\"\n",
    "full_generation_path = os.path.join(generation_path, generation_file)\n",
    "assert os.path.isfile(full_generation_path), f\"‚ùå Generation file not found: {full_generation_path}\"\n",
    "\n",
    "# === Step 1: Load the Excel file ===\n",
    "input_file = full_generation_path\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# === Step 2: Define the new structure ===\n",
    "columns = [\n",
    "    \"Name\", \"Fueltype\", \"Technology\", \"Set\", \"Country\", \"Capacity\",\n",
    "    \"Efficiency\", \"Duration\", \"Volume_Mm3\", \"DamHeight_m\",\n",
    "    \"StorageCapacity_MWh\", \"DateIn\", \"DateRetrofit\", \"DateOut\",\n",
    "    \"lat\", \"lon\", \"EIC\", \"projectID\"\n",
    "]\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# === Step 3: Map available data ===\n",
    "new_df[\"Name\"] = df[\"Central\"]\n",
    "new_df[\"Fueltype\"] = df[\"Tipo de Central\"]\n",
    "new_df[\"Technology\"] = df[\"Subtipo de Central\"]\n",
    "new_df[\"Set\"] = df[\"Sistema\"]\n",
    "new_df[\"Country\"] = \"Ecuador\"\n",
    "new_df[\"Capacity\"] = df[\"Potencia Efectiva (MW)\"]\n",
    "new_df[\"lat\"] = df[\"Latitud\"]\n",
    "new_df[\"lon\"] = df[\"Longitud\"]\n",
    "\n",
    "# === Step 4: Clean strings ===\n",
    "def clean_text(value):\n",
    "    \"\"\"Remove accents, replace spaces with underscores, and handle NaN safely.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    value = str(value)\n",
    "    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('utf-8')\n",
    "    value = value.replace(\" \", \"_\")\n",
    "    return value.strip()\n",
    "\n",
    "for col in new_df.select_dtypes(include=['object']).columns:\n",
    "    new_df[col] = new_df[col].apply(clean_text)\n",
    "\n",
    "# === Step 5: Ensure unique names ===\n",
    "def make_unique(series):\n",
    "    \"\"\"Append _2, _3, etc. to duplicated names.\"\"\"\n",
    "    counts = {}\n",
    "    unique_names = []\n",
    "    for name in series:\n",
    "        if name not in counts:\n",
    "            counts[name] = 1\n",
    "            unique_names.append(name)\n",
    "        else:\n",
    "            counts[name] += 1\n",
    "            unique_names.append(f\"{name}_{counts[name]}\")\n",
    "    return unique_names\n",
    "\n",
    "if new_df[\"Name\"].duplicated().any():\n",
    "    print(\"‚ö†Ô∏è Duplicate names detected ‚Äî renaming...\")\n",
    "    new_df[\"Name\"] = make_unique(new_df[\"Name\"])\n",
    "\n",
    "assert new_df[\"Name\"].is_unique, \"‚ùå Duplicate names still exist after renaming.\"\n",
    "\n",
    "# Temp Date In so they are by default included in the evaluation\n",
    "\n",
    "new_df[\"DateIn\"]= 2000  \n",
    "# === Step 6: Export cleaned file ===\n",
    "ppl_path = dirs[\"data/processed/generation\"]\n",
    "os.makedirs(ppl_path, exist_ok=True)\n",
    "ppl_file = os.path.join(ppl_path, \"powerplants_existing.csv\")\n",
    "new_df.to_csv(ppl_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "ppl_existent = copy.deepcopy(new_df)\n",
    "\n",
    "print(f\"‚úÖ New CSV file created and cleaned: {ppl_file}\")\n",
    "print(f\"‚úÖ All {len(new_df)} plant names are unique.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d992076",
   "metadata": {},
   "source": [
    "# Newer power plants\n",
    "New power plants that according the master plan shall come into operation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff917cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Future CSV created: c:\\Repositories\\Repos\\pypsa-earth-project\\EcuadorElectricGrid\\data\\processed\\generation\\powerplants_future.csv\n",
      "‚úÖ Rows: 30 | Unique names: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "generation_path = dirs[\"data/raw/generation\"]\n",
    "input_file = os.path.join(generation_path, \"generation_future.xlsx\")\n",
    "assert os.path.isfile(input_file), f\"‚ùå Future generation file not found: {input_file}\"\n",
    "\n",
    "\n",
    "# === Load ===\n",
    "df = pd.read_excel(input_file, sheet_name=\"Future\")\n",
    "\n",
    "# === Target structure ===\n",
    "columns = [\n",
    "    \"Name\",\n",
    "    \"Fueltype\",\n",
    "    \"Technology\",\n",
    "    \"Set\",\n",
    "    \"Country\",\n",
    "    \"Capacity\",\n",
    "    \"Efficiency\",\n",
    "    \"Duration\",\n",
    "    \"Volume_Mm3\",\n",
    "    \"DamHeight_m\",\n",
    "    \"StorageCapacity_MWh\",\n",
    "    \"DateIn\",\n",
    "    \"DateRetrofit\",\n",
    "    \"DateOut\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"EIC\",\n",
    "    \"projectID\",\n",
    "]\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# === Map available data ===\n",
    "new_df[\"Name\"] = df[\"Proyecto / Central\"]\n",
    "new_df[\"Fueltype\"] = df[\"Tipo\"]  # keep as provided (normalized below)\n",
    "new_df[\"Technology\"] = \"\"  # not provided in this sheet\n",
    "new_df[\"Set\"] = \"S.N.I.\"  # tag to distinguish dataset\n",
    "new_df[\"Country\"] = \"Ecuador\"\n",
    "new_df[\"Capacity\"] = pd.to_numeric(df[\"Potencia [MW]\"], errors=\"coerce\")\n",
    "new_df[\"DateIn\"] = pd.to_numeric(df[\"A√±o de entrada en operaci√≥n\"], errors=\"coerce\")\n",
    "new_df[\"lat\"] = pd.to_numeric(df[\"Latitud\"], errors=\"coerce\")\n",
    "new_df[\"lon\"] = pd.to_numeric(df[\"Longitud\"], errors=\"coerce\")\n",
    "\n",
    "# Empty optional fields\n",
    "for c in [\n",
    "    \"Efficiency\",\n",
    "    \"Duration\",\n",
    "    \"Volume_Mm3\",\n",
    "    \"DamHeight_m\",\n",
    "    \"StorageCapacity_MWh\",\n",
    "    \"DateRetrofit\",\n",
    "    \"DateOut\",\n",
    "    \"EIC\",\n",
    "    \"projectID\",\n",
    "]:\n",
    "    new_df[c] = np.nan\n",
    "\n",
    "\n",
    "# === String normalization (remove accents, spaces->underscores) ===\n",
    "def clean_text(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    value = str(value)\n",
    "    value = (\n",
    "        unicodedata.normalize(\"NFKD\", value).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    )\n",
    "    value = value.replace(\" \", \"_\")\n",
    "    return value.strip()\n",
    "\n",
    "\n",
    "for col in [\"Name\", \"Fueltype\", \"Technology\", \"Set\", \"Country\", \"EIC\", \"projectID\"]:\n",
    "    new_df[col] = new_df[col].apply(clean_text)\n",
    "\n",
    "\n",
    "# === Ensure unique plant names ===\n",
    "def make_unique(series):\n",
    "    counts = {}\n",
    "    out = []\n",
    "    for name in series:\n",
    "        if name not in counts:\n",
    "            counts[name] = 1\n",
    "            out.append(name)\n",
    "        else:\n",
    "            counts[name] += 1\n",
    "            out.append(f\"{name}_{counts[name]}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "if new_df[\"Name\"].duplicated().any():\n",
    "    print(\"‚ö†Ô∏è Duplicate names detected ‚Äî renaming...\")\n",
    "    # new_df[\"Name\"] = make_unique(new_df[\"Name\"])\n",
    "\n",
    "assert new_df[\"Name\"].is_unique, \"‚ùå Duplicate names still exist after renaming.\"\n",
    "\n",
    "tech = {\n",
    "    \"Hidroelectrico\": \"Embalse\",\n",
    "    \"Termoelectrico\": \"MCI\",\n",
    "    \"Eolico\": \"Eolica\",\n",
    "    \"ERNC\": \"Fotovoltaica\",\n",
    "    \"Nuclear\": \"Nuclear\",\n",
    "}\n",
    "\n",
    "for i, row in new_df.iterrows():\n",
    "    new_df.at[i,\"Technology\"] = tech[row[\"Fueltype\"]]\n",
    "\n",
    "# === Export ===\n",
    "\n",
    "# === Step 6: Export cleaned file ===\n",
    "ppl_path = dirs[\"data/processed/generation\"]\n",
    "os.makedirs(ppl_path, exist_ok=True)\n",
    "out_file = os.path.join(ppl_path, \"powerplants_future.csv\")\n",
    "\n",
    "# Use UTF-8 (PyPSA-friendly). If you want Excel-safe accents, use encoding='utf-8-sig'.\n",
    "new_df.to_csv(out_file, index=False, encoding=\"utf-8\")\n",
    "ppl_future = copy.deepcopy(new_df)\n",
    "print(f\"‚úÖ Future CSV created: {out_file}\")\n",
    "print(f\"‚úÖ Rows: {len(new_df)} | Unique names: {new_df['Name'].is_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0b81c",
   "metadata": {},
   "source": [
    "Combine all power plants into a single File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74e46b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Combined shape: (347, 18)\n",
      "üìã Columns: ['Name', 'Fueltype', 'Technology', 'Set', 'Country', 'Capacity', 'Efficiency', 'Duration', 'Volume_Mm3', 'DamHeight_m', 'StorageCapacity_MWh', 'DateIn', 'DateRetrofit', 'DateOut', 'lat', 'lon', 'EIC', 'projectID']\n",
      "‚úÖ Combined power plants file saved at:\n",
      "   c:\\Repositories\\Repos\\pypsa-earth-project\\EcuadorElectricGrid\\data\\processed\\generation\\powerplants_all.csv\n",
      "‚úÖ Total plants: 347\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Define the output path ===\n",
    "ppl_path = dirs[\"data/processed/generation\"]\n",
    "os.makedirs(ppl_path, exist_ok=True)\n",
    "out_file = os.path.join(ppl_path, \"powerplants_all.csv\")\n",
    "all_ppl_file = out_file\n",
    "# === Step 2: Concatenate vertically ===\n",
    "# (both DataFrames must have the same columns)\n",
    "combined_df = pd.concat([ppl_existent, ppl_future], axis=0, ignore_index=True)\n",
    "\n",
    "# === Step 3: Verify structure ===\n",
    "print(f\"üß© Combined shape: {combined_df.shape}\")\n",
    "print(f\"üìã Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# === Step 4: Export to CSV ===\n",
    "# Use utf-8-sig for Excel compatibility if needed\n",
    "combined_df.to_csv(out_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"‚úÖ Combined power plants file saved at:\\n   {out_file}\")\n",
    "print(f\"‚úÖ Total plants: {len(combined_df)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
